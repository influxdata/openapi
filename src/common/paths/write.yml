post:
  operationId: PostWrite
  tags:
    - Data I/O endpoints
    - Write
  summary: Write data
  description: |
    Writes data to a bucket.

    Use this endpoint to send data in [line protocol]({{% INFLUXDB_DOCS_URL %}}/reference/syntax/line-protocol/) format to InfluxDB.

    #### InfluxDB Cloud

    - Does the following when you send a write request:

      1. Validates the request and queues the write.
      2. If queued, responds with _success_ (HTTP `2xx` status code); _error_ otherwise.
      3. Handles the delete asynchronously and reaches eventual consistency.

      To ensure that InfluxDB Cloud handles writes and deletes in the order you request them,
      wait for a success response (HTTP `2xx` status code) before you send the next request.

      Because writes and deletes are asynchronous, your change might not yet be readable
      when you receive the response.

    #### InfluxDB OSS

    - Validates the request and handles the write synchronously.
    - If all points were written successfully, responds with HTTP `2xx` status code;
      otherwise, returns the first line that failed.

    #### Required permissions

    - `write-buckets` or `write-bucket BUCKET_ID`.

     *`BUCKET_ID`* is the ID of the destination bucket.

    #### Rate limits (with InfluxDB Cloud)

    `write` rate limits apply.
    For more information, see [limits and adjustable quotas](https://docs.influxdata.com/influxdb/cloud/account-management/limits/).

    #### Related guides

    - [Write data with the InfluxDB API]({{% INFLUXDB_DOCS_URL %}}/write-data/developer-tools/api)
    - [Optimize writes to InfluxDB]({{% INFLUXDB_DOCS_URL %}}/write-data/best-practices/optimize-writes/)
    - [Troubleshoot issues writing data]({{% INFLUXDB_DOCS_URL %}}/write-data/troubleshoot/)
  requestBody:
    description: |
      Data in line protocol format.

      To send compressed data, do the following:

        1. Use [GZIP](https://www.gzip.org/) to compress the line protocol data.
        2. In your request, send the compressed data and the
           `Content-Encoding: gzip` header.

      #### Related guides

      - [Best practices for optimizing writes]({{% INFLUXDB_DOCS_URL %}}/write-data/best-practices/optimize-writes/)
    required: true
    content:
      text/plain:
        schema:
          type: string
          format: byte
        examples:
          plain-utf8:
            value: |
              airSensors,sensor_id=TLM0201 temperature=73.97038159354763,humidity=35.23103248356096,co=0.48445310567793615 1630424257000000000
              airSensors,sensor_id=TLM0202 temperature=75.30007505999716,humidity=35.651929918691714,co=0.5141876544505826 1630424257000000000
  parameters:
    - $ref: "../../common/parameters/TraceSpan.yml"
    - in: header
      name: Content-Encoding
      description: |
        The compression applied to the line protocol in the request payload.
        To send a GZIP payload, pass `Content-Encoding: gzip` header.
      schema:
        type: string
        description: |
          Content coding.
          Use `gzip` for compressed data or `identity` for unmodified, uncompressed data.
        default: identity
        enum:
          - gzip
          - identity
    - in: header
      name: Content-Type
      description: |
        The format of the data in the request body.
        To send a line protocol payload, pass `Content-Type: text/plain; charset=utf-8`.
      schema:
        type: string
        description: |
          `text/plain` is the content type for line protocol. `UTF-8` is the default character set.
        default: text/plain; charset=utf-8
        enum:
          - text/plain
          - text/plain; charset=utf-8
    - in: header
      name: Content-Length
      description: |
        The size of the entity-body, in bytes, sent to InfluxDB.
        If the length is greater than the `max body` configuration option,
        the server responds with status code `413`.
      schema:
        type: integer
        description: The length in decimal number of octets.
    - in: header
      name: Accept
      description: |
        The content type that the client can understand.
        Writes only return a response body if they fail--for example,
        due to a formatting problem or quota limit.

        #### InfluxDB Cloud

          - Returns only `application/json` for format and limit errors.
          - Returns only `text/html` for some quota limit errors.

        #### InfluxDB OSS

          - Returns only `application/json` for format and limit errors.

        #### Related guides

        - [Troubleshoot issues writing data]({{% INFLUXDB_DOCS_URL %}}/write-data/troubleshoot/)
      schema:
        type: string
        description: Error content type.
        default: application/json
        enum:
          - application/json
    - in: query
      name: org
      description: |
        The destination organization for writes.
        InfluxDB writes all points in the batch to this organization.
        If you pass both `orgID` and `org`, they must both be valid.

        #### InfluxDB Cloud

        - Doesn't require `org` or `orgID`.
        - Writes to the bucket in the organization associated with the authorization (API token).

        #### InfluxDB OSS

        - Requires either the `org` parameter or the `orgID` parameter.
        - InfluxDB writes all points in the batch to this organization.
      required: true
      schema:
        type: string
        description: The organization name or ID.
    - in: query
      name: orgID
      description: |
        The ID of the destination organization for writes.
        If you pass both `orgID` and `org`, they must both be valid.

        #### InfluxDB Cloud

        - Doesn't require `org` or `orgID`.
        - Writes to the bucket in the organization associated with the authorization (API token).


        #### InfluxDB OSS

        - Requires either the `org` parameter or the `orgID` parameter.
        - InfluxDB writes all points in the batch to this organization.

      schema:
        type: string
    - in: query
      name: bucket
      description: |
        The destination bucket for writes.
        InfluxDB writes all points in the batch to this bucket.
      required: true
      schema:
        type: string
        description: The bucket name or ID.
    - in: query
      name: precision
      description: The precision for unix timestamps in the line protocol batch.
      schema:
        $ref: "../../common/schemas/WritePrecision.yml"
  responses:
    "204":
      description: |
        Success.

        #### InfluxDB Cloud

        - Validated and queued the request.
        - Handles the write asynchronously - the write might not have completed yet.

        #### InfluxDB OSS

        - Successfully wrote all points in the batch.

        #### Related guides

        - [How to check for write errors]({{% INFLUXDB_DOCS_URL %}}/write-data/troubleshoot/)
    "400":
      description: |
        Bad request. The response body contains detail about the error.

        InfluxDB returns this error if the line protocol data in the request is malformed.
        The response body contains the first malformed line in the data, and indicates what was expected.
        For partial writes, the number of points written and the number of points rejected are also included.
        For more information, check the `rejected_points` measurement in your `_monitoring` bucket.

        #### InfluxDB Cloud

        - Returns this error for bucket schema conflicts.

        #### InfluxDB OSS

        - Returns this error if `org` or `orgID` doesn't match an organization.

      content:
        application/json:
          schema:
            $ref: "../../common/schemas/LineProtocolError.yml"
          examples:
            measurementSchemaFieldTypeConflict:
              summary: (Cloud) field type conflict thrown by an explicit bucket schema
              value: {
               "code": "invalid",
               "message": "partial write error (2 written): unable to parse 'air_sensor,service=S1,sensor=L1 temperature=\"90.5\",humidity=70.0 1632850122': schema: field type for field \"temperature\" not permitted by schema; got String but expected Float"
              }
            orgNotFound:
              summary: (OSS) organization not found
              value: {
                "code":"invalid",
                "message":"failed to decode request body: organization not found"
              }
    "413":
      description: |
       The request payload is too large.
       InfluxDB rejected the batch and did not write any data.

       #### InfluxDB Cloud:

        - Returns this error if the payload exceeds the 50MB size limit.
        - Returns `Content-Type: text/html` for this error.

       #### InfluxDB OSS:

        - Returns this error only if the [Go (golang) `ioutil.ReadAll()`](https://pkg.go.dev/io/ioutil#ReadAll) function raises an error.
        - Returns `Content-Type: application/json` for this error.
      content:
        # application/json must be listed first for the influx-cli codegen to work properly, see https://github.com/influxdata/openapi/pull/253
        application/json:
          schema:
            $ref: "../../common/schemas/LineProtocolLengthError.yml"
          examples:
            dataExceedsSizeLimitOSS:
              summary: InfluxDB OSS response
              value: |
                {"code":"request too large","message":"unable to read data: points batch is too large"}
        text/html:
          schema:
            type: string
          examples:
            dataExceedsSizeLimit:
              summary: InfluxDB Cloud response
              value: |
                <html>
                  <head><title>413 Request Entity Too Large</title></head>
                  <body>
                    <center><h1>413 Request Entity Too Large</h1></center>
                    <hr>
                    <center>nginx</center>
                  </body>
                </html>
    "429":
      description: |
        Too many requests.

        #### InfluxDB Cloud

          - Returns this error if a **read** or **write** request exceeds your plan's [adjustable service quotas](https://docs.influxdata.com/influxdb/cloud/account-management/limits/#adjustable-service-quotas)
            or if a **delete** request exceeds the maximum [global limit](https://docs.influxdata.com/influxdb/cloud/account-management/limits/#global-limits).
          - For rate limits that reset automatically, returns a `Retry-After` header that describes when to try the write again.
          - For limits that can't reset (for example, **cardinality limit**), doesn't return a `Retry-After` header.

          Rates (data-in (writes), queries (reads), and deletes) accrue within a fixed five-minute window.
          Once a rate limit is exceeded, InfluxDB returns an error response until the current five-minute window resets.

        #### InfluxDB OSS

          - Doesn't return this error.
      headers:
        Retry-After:
          description: Non-negative decimal integer indicating seconds to wait before retrying the request.
          schema:
            type: integer
            format: int32
    "503":
      description: |
        Service unavailable.

        - Returns this error if
          the server is temporarily unavailable to accept writes.
        - Returns a `Retry-After` header that describes when to try the write again.
      headers:
        Retry-After:
          description: Non-negative decimal integer indicating seconds to wait before retrying the request.
          schema:
            type: integer
            format: int32
    "401":
      $ref: "../responses/AuthorizationError.yml"
    "404":
      $ref: "../responses/ResourceNotFoundError.yml"
    "500":
      $ref: "../responses/InternalServerError.yml"
    default:
      $ref: "../responses/ServerError.yml"
